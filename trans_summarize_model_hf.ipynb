{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is created to showcast my continuus upskill in LLM\n",
    "## Auther: Hussein Al-bandawi\n",
    "## Date: 29:07:2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 13:00:19.640000 10560 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "from transformers import pipeline\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9316b106ea994217af70e5e9542e3245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--facebook--blenderbot-400M-distill. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e8ee48e0f74813bc1d388f85a91a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22829cb49c3443d39d53cef9badc7829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc301f1652b40b5a65c6e61a66038dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190aa5a442ca4ba89f721910f68abd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a436c1680693463294c7ee6e10eeb772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b767616db8492eb9ac5c9c6663bb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c39c0feff344c4584287d7f4cfa2bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf07cbf7cb14d3284a920d2db1a8d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatbot = pipeline(task=\"conversational\",\n",
    "                   model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let define the user message\n",
    "user_message = \"\"\"\n",
    "What should I wear in winter?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 9755f115-8956-4689-9d7d-dbb2a1eeacce\n",
      "user: \n",
      "What should I wear in winter?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the converastion fun from transformaer\n",
    "from transformers import Conversation\n",
    "conversation = Conversation(user_message)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 9755f115-8956-4689-9d7d-dbb2a1eeacce\n",
      "user: \n",
      "What should I wear in winter?\n",
      "\n",
      "assistant:  I like to wear sweaters in the winter. I like the warmth and warmth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation = chatbot(conversation)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_message(\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"\n",
    "What else do you recommend?\n",
    "\"\"\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 9755f115-8956-4689-9d7d-dbb2a1eeacce\n",
      "user: \n",
      "What should I wear in winter?\n",
      "\n",
      "assistant:  I like to wear sweaters in the winter. I like the warmth and warmth.\n",
      "user: \n",
      "What else do you recommend?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of chatbot intro:\n",
    "# Now I will try to use tasks such as translate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0fcd02b00a462d983c826572d1016e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--facebook--nllb-200-distilled-600M. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965329411fe74a69939c1c6c5197f640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd6f2c5441342038d8f1b9c6ea31148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03dbf90f972446798b086dd41627232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26b9374902f428b8b6201c5deaa2be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)6cea38b9e3d5efcdcb9c251d6b40538e1aab555a:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb65ed9c0648deb144d1ce70e8429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edaf84e743eb4d0c8b92cd81935046bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translator = pipeline(task=\"translation\",\n",
    "                      model=\"facebook/nllb-200-distilled-600M\",\n",
    "                      torch_dtype=torch.bfloat16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is model from hugging face NLLB: No Language Left Behind: 'nllb-200-distilled-600M'.\n",
    "### I will use it to translate from enggilish to other languages  -_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here write down the text to be translated\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now will feed it to get the translation\n",
    "text_translated = translator(text,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"fra_Latn\")\n",
    "## second arg for source language, for the language to be traslate from\n",
    "## second arg for targeted language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To choose other languages,head to the other language codes on the page: \n",
    "https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Mon chiot est adorable, ton chaton est mignon, son panda est ami, sa lamme est attentive, nous avons tous de beaux animaux de compagnie.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Mon chiot est adorable, ton chaton est mignon, son '\n",
      "                      'panda est ami, sa lamme est attentive, nous avons tous '\n",
      "                      'de beaux animaux de compagnie.'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint # this function will print in a better formatted text\n",
    "pprint.pprint(text_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'كلبي جميل, قطتك لطيفة, غاندها صديقة, لامه متفكره, كلنا '\n",
      "                      'لدينا حيوانات أليفة لطيفة'}]\n"
     ]
    }
   ],
   "source": [
    "# let try the arabic language\n",
    "text_translated = translator(text,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"acm_Arab\")\n",
    "pprint.pprint(text_translated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now here we move to summarizing the text, which is a very importnat task for LLM\n",
    "\n",
    "### Build the summarization pipeline using  Transformers Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3604f50f7c74b349854e744e95339d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9387ff28216e42e784bf38e86c330372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c23ef0e2bc4d339f16080bcc1dd7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad3c2df24b4bf5af0ca43c28502831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3749e4b953a4c8b891bd8b5b98e5986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac5aa792953444b8cc0084239efcb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First step is to define the summarizer according to \n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      torch_dtype=torch.bfloat16)\n",
    "# by setting task to summarization and selecting the model form huggingface, and compressing the torch model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"\"\" Technical Skills:\n",
    "\n",
    "Proficiency in programming languages such as Python, Java, or C++.\n",
    "Solid experience with machine learning frameworks like TensorFlow, PyTorch, or scikit-learn.\n",
    "Strong knowledge of algorithms, data structures, and computational mathematics.\n",
    "Experience with data manipulation tools such as Pandas, NumPy, and data visualization libraries (e.g., Matplotlib, Seaborn).\n",
    "Familiarity with cloud platforms (AWS, Google Cloud, or Azure) and machine learning deployment tools (e.g., TensorFlow Serving, Kubernetes).\n",
    "Familiarity with financial datasets, tools, and concepts (e.g., time-series data, risk assessment models, fraud detection).\n",
    "AI Techniques: Experience with a variety of AI techniques such as supervised learning, deep learning, reinforcement learning, and natural language processing (NLP).\n",
    "Data-Driven Mindset: Strong analytical and problem-solving skills with the ability to interpret and transform data into actionable insights.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Strong knowledge of algorithms, data structures, and '\n",
      "                  'computational mathematics. Strong analytical and '\n",
      "                  'problem-solving skills with the ability to interpret and '\n",
      "                  'transform data into actionable insights.'}]\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(text,\n",
    "                     min_length=10,\n",
    "                     max_length=100)\n",
    "pprint.pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in E:/lamini/LLM-Finetuning/.git/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'LLM-Finetubning-code.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/LLM-Finetubning-code-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/trans_summarize_model_hf-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'trans_summarize_model_hf.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'utilities.py', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 792af47] Commit from Jupyter\n",
      " 9 files changed, 2171 insertions(+), 153 deletions(-)\n",
      " create mode 100644 .ipynb_checkpoints/LLM-Finetubning-code-checkpoint.ipynb\n",
      " create mode 100644 .ipynb_checkpoints/README-checkpoint.md\n",
      " create mode 100644 .ipynb_checkpoints/Source_code-checkpoint.ipynb\n",
      " create mode 100644 .ipynb_checkpoints/The_project_LLM-checkpoint\n",
      " create mode 100644 .ipynb_checkpoints/trans_summarize_model_hf-checkpoint.ipynb\n",
      " create mode 100644 __pycache__/utilities.cpython-312.pyc\n",
      " create mode 100644 trans_summarize_model_hf.ipynb\n",
      " create mode 100644 utilities.py\n"
     ]
    }
   ],
   "source": [
    "# let push it to github\n",
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Commit from Jupyter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Projectisready/LLM-Finetuning.git\n",
      "   0310e8e..792af47  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/Projectisready/LLM-Finetuning.git\n",
    "#!git remote add origin github.com/Projectisready/LLM-Finetuning.git\n",
    "#!git branch -M main\n",
    "#!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'trans_summarize_model_hf.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of '.ipynb_checkpoints/text-similarity-test-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'text-similarity-test.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   trans_summarize_model_hf.ipynb\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/text-similarity-test-checkpoint.ipynb\n",
      "\ttext-similarity-test.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git push\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   trans_summarize_model_hf.ipynb\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/text-similarity-test-checkpoint.ipynb\n",
      "\ttext-similarity-test.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
